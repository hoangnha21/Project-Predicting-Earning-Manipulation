---
title: 'Earning Manipulation by Indian Firm'
author: "Nha Nguyen"
date: '2022-11-14'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r Load, combine and rename datasets}
library(readxl)
library(ISLR)
library(caret)
library(pROC)
library(ROSE)
library(robustbase)
library(smotefamily)
library(ROCR)
library(rpart)
library(rpart.plot)

#load the excel file 
library(readxl)
databook=read_excel('/Users/hoangnha218/Desktop/HW3/IMB579-XLS-ENG.xlsx')
#Read the 2nd Excel sheet from databook "Manipulator"
manipulator<-read_excel('/Users/hoangnha218/Desktop/HW3/IMB579-XLS-ENG.xlsx',sheet="Manipulator")
#Read the 3rd Excel sheet from databook "Non-manipulator"
nonmanipulator<-read_excel('/Users/hoangnha218/Desktop/HW3/IMB579-XLS-ENG.xlsx',sheet="Non-Manipulator")
#Read the 4th Excel sheet from databook "Complete Data"
complete.data<- read_excel('/Users/hoangnha218/Desktop/HW3/IMB579-XLS-ENG.xlsx',sheet=4)
#Read the 5th Excel sheet from databook "Sample for Model Development"
sample.data<-read_excel('/Users/hoangnha218/Desktop/HW3/IMB579-XLS-ENG.xlsx',sheet=5)

```

###{Question 1}
#According to the Beneish Model, known as 'M-Score Model': M=-4.84+0.92DSRI+0.528GMI+0.404AQI+0.892SGI+0.115DEPI-0.172SGAI+4.679TATA-0.327LVGI

###{Question 1} Answer

#According to the given dataset, it shows that the number of observations for 'Manipulator' and 'Non-Mamiplators' is 39 and 1200 respectively. This results in data imbalance.

#The acccuracy of the model on the complete set is 71%, which is not a good performance indicator of the model due to the issue of the imbalance data is not taken into consideration. That's why the Beneish model developed in 1999 is not relevant to Indian data as Beneish model developed in 1999 gives less accuracy when compared to modern machine learning algorithms. Other drawbacks include that Beneish model uses probit model to predict earning manipulations which is supervised learning algorithm. Also, the main disadvantage of beneish model is that it cannot handle unbalanced data and the data provided to us relating to Indian banks is highly unbalanced.

# That's why our group's objective is to develop Logistic Regression and Classification Tree models to give better accuracy for the Beneish model and address the imbalance data.

###{Question 2} Answer

#The scenarios where the number of observations belonging to one class is significantly lower than the other classes are called class-imbalance problem.

#In these scenarios, the common issues that we may face are:
#-The majority of models developed using unbalanced data will be biased towards forecasting the larger class or classes and, in many instances, may completely overlook the smaller class or classes.
#-Machine learning models will often overclassify the larger classes due to their enhanced prior probability when there is a class imbalance in the training data. Because of this, examples of the smaller classes are frequently misclassified more frequently than instances of the bigger classes. 
#only likely to predict only the majority class data.
#high chance of misclassification of the minority class, only in the event where the predicted event belong to the smaller class, resulting in the reduction of model's accuracy.

#Techniques that handle the class-imbalance data:
##Resampling technique
#We can deploy 'imformed oversampling:Synthetic Minority Over Sampling Technique (SMOT)' where a subset of data is taken from the minority class as an example and then create a new synthetic similar instances. This technique helps reduce over-fitting problem.

##Bagging based
#We can also use 'bagging based' technique to generate different training samples, where we train each sample using bootstrapped algorithm. This technique reduces over-fitting and variance


``` {r Question 3}
# primary analysis of the dataset
dim(sample.data)
str(sample.data)
summary(sample.data)

#Replace '-' in the column name 'C-MANIPULATOR' to "C_MANIPULATOR"
names(sample.data)[names(sample.data) == "C-MANIPULATOR"] <- "C_MANIPULATOR"
names(complete.data)[names(complete.data) == "C-MANIPULATOR"] <- "C_MANIPULATOR"
names(complete.data)[names(complete.data) == 'Company ID'] <- 'CID'
names(sample.data)[names(sample.data) == 'Company ID'] <- 'CID'
str(sample.data)

#Check for NA values
colSums(is.na(sample.data)) 

#Change the Manipulator column values to numeric along with its type
sample.data$Manipulator <- ifelse(sample.data$Manipulator == "Yes", 1, 0)
df <- data.frame(sample.data)

#Convert target variable to factor type
df$C_MANIPULATOR <- as.factor(df$C_MANIPULATOR)
str(df)

#Check the count of target variable's classes
table(df$C_MANIPULATOR)
prop.table(table(df$C_MANIPULATOR))

### Objective: Developing Logistic Regression Model on sample data ###

#Classification model before balancing
#Divide the data into train and test data
set.seed(1234)
SIndx <- sample(2, nrow(sample.data), replace = TRUE, prob = c(0.65,0.35))
TrainIn <- df[SIndx==1, ]
TestIn <- df[SIndx==2, ]
str(TrainIn)
table(TrainIn$C_MANIPULATOR)
prop.table(table(TrainIn$C_MANIPULATOR))

# Variable selection for Logistic Model 

full <- glm(C_MANIPULATOR ~., data = TrainIn, family = "binomial")
null <- glm(C_MANIPULATOR ~1, data = TrainIn, family = "binomial")
step(null, scope = list(lower = null, upper = full), direction = "forward")

#we will run our model using only these important input variables

sampleeemodel <- glm(C_MANIPULATOR~DSRI + SGI + ACCR + AQI + GMI , data= sample.data, family = "binomial")
summary(sampleeemodel)
```
#Output of Logistic Regression Model:
#AIC: 131.77
#Important Variables: DSRI,SGI,ACCR and AQI
#Null Deviance: 205.58  on 219  degrees of freedom
#Residual Deviance: 119.77  on 214  degrees of freedom

``` {r Question 3 (Cont)}
#Using Treebag Model by Cross Validation

#Accuracy for training data
optn <- trainControl(method = "cv", number = 5)
tbModel <- train(C_MANIPULATOR ~ ., data = TrainIn, method = "treebag", trControl = optn)
PREDICTTT <- names(TrainIn)[names(TrainIn) != 'C_MANIPULATOR']
pred <- predict(tbModel$finalModel, TestIn[, PREDICTTT])
auc <- roc(TestIn$C_MANIPULATOR, pred)
print(auc)

#Accuracy on Test Data
str(TestIn)
table(TestIn$C_MANIPULATOR)
prop.table(table(TestIn$C_MANIPULATOR))

optnTest <- trainControl(method = "cv", number = 5)
tbTestModel <- train(C_MANIPULATOR ~ ., data = TestIn, method = "treebag", trControl = optn)
PREDICTTTTest <- names(TestIn)[names(TestIn) != 'C_MANIPULATOR']
predTest <- predict(tbTestModel$finalModel, TestIn[, PREDICTTTTest])
aucTest <- roc(TestIn$C_MANIPULATOR, predTest)
print(aucTest)

#Using Synthetic Minority Oversampling Technique (SMOTE) statistical technique
### Objective: design a new sample.data for the modeling ###
smote_train <- TrainIn
smote_train$C_MANIPULATOR <- as.factor(smote_train$C_MANIPULATOR)
table(smote_train$C_MANIPULATOR)
prop.table(table(smote_train$C_MANIPULATOR))
str(smote_train)

smote_train <- SMOTE(smote_train[-11], smote_train$C_MANIPULATOR)
smote_new <- smote_train$data
table(smote_new$class)
prop.table(table(smote_new$class))
```

``` {r Question 4} 
### Objective: Evaluate performance of the logistic regression model ###
# Logistic Regression for the data Balanced by Smote
# We use Accuracy measure to evaluate performance. 
# Along AIC. 
smote_main <- glm(as.factor(class) ~ ., data = smote_new, family = "binomial")
summary(smote_main)

smote_predict <- predict(smote_main, type = "response")
smote_predict <- ifelse(smote_predict > 0.50, 1, 0)
confusionMatrix(as.factor(smote_new$class), as.factor(smote_predict), positive = "1")
## The model gives 100% accuracy of Training Data

#Logistic Regression on Test Data
#Using SMOTE - will design a new Test sample.data for the modeling
smote_test <- TestIn
smote_test$C_MANIPULATOR <- as.factor(smote_test$C_MANIPULATOR)
table(smote_test$C_MANIPULATOR)
prop.table(table(smote_test$C_MANIPULATOR))
str(smote_test)

smote_test <- SMOTE(smote_test[-11], smote_test$C_MANIPULATOR)
smote_testNew <- smote_test$data
table(smote_testNew$class)
prop.table(table(smote_testNew$class))

#Logistic Regression for the data Balanced by Smote
smote_testLogistic <- glm(as.factor(class) ~ ., data = smote_testNew, family = "binomial")
summary(smote_testLogistic)

smote_testPredict <- predict(smote_testLogistic, type = "response")
smote_testPredict <- ifelse(smote_testPredict > 0.50, 1, 0)
confusionMatrix(as.factor(smote_testNew$class), as.factor(smote_testPredict), positive = "1")
## The model gives 100% accuracy for Test Data
```

``` {r Question 7} 
### Objective: Develop Decision Tree Model###
library(rpart)
library(rpart.plot)


TrainModel111<-rpart( C_MANIPULATOR ~ + DSRI + AQI + GMI + SGI + SGAI + ACCR + DEPI + LEVI + DEPI  , data=sample.data, parms = list(split = "information"), control = rpart.control(minsplit = 5, cp=0.01)) 
rpart.plot(TrainModel111) 
print(TrainModel111)


#Accuracy for the Decision Tree

Train_data_pred1<-predict(TrainModel111, TrainIn)
Train_data_accuracy1<-round(mean(TrainIn$C_MANIPULATOR==Train_data_pred1)*100,2)
Train_data_accuracy1
#Accuracy = 76.36%

Test_data_pred2<-predict(TrainModel111, TestIn)
Test_data_accuracy2<-round(mean(TestIn$C_MANIPULATOR==Test_data_pred2)*100,2)
Test_data_accuracy2
#Accuracy = 77.27%

###### Random Forest Model #######

library(randomForest)
library(ROSE)

# Sampling Test and Train data 
sample.data$`CID`<- NULL
set.seed(1234)
index <- sample(2, nrow(sample.data), replace = TRUE, prob = c(0.65,0.35))
rf_train <- sample.data[index == 1,]
rf_test <- sample.data[index == 2,]

# Balancing the data by Oversampling 
over_sample_rf <- ovun.sample(C_MANIPULATOR~., data = rf_train, method = "over", N= 250)$data
table(over_sample_rf$C_MANIPULATOR)

randomforest1 = randomForest(C_MANIPULATOR~., 
                  data = over_sample_rf, ntree = 100, 
                  proximity = TRUE, replace= TRUE, 
                  importance = TRUE, 
                  mtry = sqrt(ncol(over_sample_rf)))
randomforest2 = randomForest(C_MANIPULATOR~ DSRI + SGI + ACCR, 
                           data = over_sample_rf, ntree = 100, 
                           proximity = TRUE, replace= TRUE, 
                           importance = TRUE, 
                           mtry = sqrt(ncol(over_sample_rf)))

print(randomforest1)
plot(randomforest1)
plot(randomforest2)

rf_test_pred <- predict(randomforest1, newdata = rf_test)
rf_test_pred
rf_table <- table(rf_test_pred, newdata = rf_test$C_MANIPULATOR)

```

``` {Question 8}
### Objective: Develop a Logistic Regression model for Complete data ###

table(complete.data$C_MANIPULATOR)
colSums(is.na(complete.data))

# Change the Manipulator column values to numeric along with its type
complete.data$MANIPULATOR <- ifelse(complete.data$Manipulater == "Yes", 1, 0)
str(complete.data)

# Splitting the complete data into Training and Testing 
set.seed(123)
index1 = sample(2, nrow(complete.data), replace = TRUE, prob = c(0.8,0.2))
Train_complete = complete.data[index1 == 1, ]
nrow(Train_complete)
table(Train_complete$C_MANIPULATOR)
Test_complete = complete.data[index1 == 2,]
nrow(Test_complete)
table(Test_complete$C_MANIPULATOR)

# Building Logistic Regression model 
L_Train_Complete <- glm(C_MANIPULATOR ~ ., 
                       data = Train_complete, 
                       family = "binomial")
summary(L_Train_Complete)

#Using oversampling for predicting 
L_Train_over <- ovun.sample(C_MANIPULATOR~ .,
                           data = Train_complete,
                           method = "over", 
                           N=1986)$data
table(L_Train_over$C_MANIPULATOR)

# Variable selection for Logistic Model 

full <- lm(C_MANIPULATOR ~., data = L_Train_over, family = "binomial")
null <- lm(C_MANIPULATOR ~1, data = L_Train_over, family = "binomial")

step(null, scope = list(lower = null, upper = full), direction = "forward")

#using forward Method to select  variable

L_Train_Complete_variable <- glm(C_MANIPULATOR ~  DSRI + ACCR + SGI + AQI,
                                data = L_Train_over, 
                                family = "binomial")
summary(L_Train_Complete_variable)

# Deviance for the model
Lt <- summary(L_Train_Complete_variable)$deviance
Lt

# Predict test data based on model
T_pred_variable = predict.glm(L_Train_Complete_variable, newdata = Test_complete, type="response")
T_pred_variable

#Plotting ROC Curve
roc_pred = prediction(T_pred_variable, Test_complete$C_MANIPULATOR)
roc_perf = performance(roc_pred, "tpr", "fpr")
plot(roc_perf, col = "blue")

#calculating Optimal Cutoff
opt.cut = function(roc_perf, roc_pred){
  cut.ind = mapply(FUN=function(x, y, p){
    d = (x - 0)^2 + (y-1)^2
    ind = which(d == min(d))
    c(sensitivity = y[[ind]], specificity = 1-x[[ind]], cutoff = p[[ind]])
  }, roc_perf@x.values, roc_perf@y.values, roc_pred@cutoffs)}
print(opt.cut(roc_perf, roc_pred))
#sensitivity 1.0000000
#specificity 0.9033816
#cutoff      0.5978656

#Using the cutoff Point to Plot Confusion Matrix
T_pred_variable$C_MANIPULATOR = ifelse(T_pred_variable> 0.5978656,1,0)

pt<-table(T_pred_variable$C_MANIPULATOR, Test_complete$C_MANIPULATOR, dnn = c("Predicted","Actual"))
pt
confusionMatrix(ptab,positive = "1")
# We Get 95% Accuracy
